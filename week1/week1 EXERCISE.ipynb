{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "openai = OpenAI()\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e670e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_answer(llm, question, model):\n",
    "    stream = llm.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a supremely helpful expert on every topic. Answer my question\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "          ],\n",
    "        stream=True\n",
    "    )    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided code snippet is using a Python feature called \"generator expressions\" in combination with the `yield from` statement. Let's break down the code:\n",
       "\n",
       "1. **Generator Expression:** The part inside the braces `{...}` is a set comprehension. It iterates over each `book` in a collection called `books`, and for each `book`, it retrieves the value associated with the `\"author\"` key using `book.get(\"author\")`. If the `\"author\"` key exists and its value is not `None` (or if it is an empty string), that value is included in the resulting set. The condition `if book.get(\"author\")` acts as a filter to ensure that only valid author values are included. \n",
       "\n",
       "    - For example, if `books` contained:\n",
       "      ```python\n",
       "      books = [\n",
       "          {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "          {\"title\": \"Book 2\", \"author\": None},\n",
       "          {\"title\": \"Book 3\", \"author\": \"Author B\"},\n",
       "          {\"title\": \"Book 4\", \"author\": \"\"},\n",
       "          {\"title\": \"Book 5\", \"author\": \"Author C\"},\n",
       "      ]\n",
       "      ```\n",
       "      The resulting set of authors would be `{\"Author A\", \"Author B\", \"Author C\"}`.\n",
       "\n",
       "2. **Set:** The braces `{...}` indicate that this is a set comprehension, which means the result is a set containing unique authors. If there are duplicate authors among the books, they will only appear once in the set.\n",
       "\n",
       "3. **`yield from` Statement:** The `yield from` keyword is used in a generator to yield all values from an iterable (in this case, the set of authors). This means that the function containing this code will yield each author one by one when iterated over.\n",
       "\n",
       "### Summary\n",
       "In summary, this line of code collects the unique authors from a list of `books` where the authors are specified (i.e., not `None` or empty) and yields them one by one as needed. This is useful for creating a generator that allows for lazy evaluation and efficient iteration over authors without needing to build and store an entire list of them in memory at once."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "stream_answer(openai, question, MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This line of code uses a feature of Python 3.10 called **yield from**, along with a **generator expression**, which is a shorthand way to create a generator function.\n",
       "\n",
       "**Breaking it down:**\n",
       "\n",
       "* `book.get(\"author\")`: This tries to get the value associated with the key `\"author\"` from each dictionary (`book`) that you're iterating over.\n",
       "* `{... for book in books ... }`: This is a **generator expression**, which is similar to a list comprehension, but instead of building a new Python object, it builds an iterator (a generator).\n",
       "* `yield from {...}`: This is the magic part. When used inside a function or another generator, `yield from` \"sub-generates\" a sequence yielded by another iterator.\n",
       "\n",
       "So, putting it all together:\n",
       "\n",
       "```python\n",
       "def get_authors(books):\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "```\n",
       "\n",
       "This code does two main things:\n",
       "\n",
       "1. **Filtering**: It filters out any dictionaries (`book`) that don't have an `\"author\"` key.\n",
       "2. **Yielding values iteratively**: For each remaining dictionary, it yields their corresponding author value as a string (or `None` if the value is missing).\n",
       "\n",
       "**Why is this useful?**\n",
       "\n",
       "This code allows you to efficiently iterate over the authors of multiple books at once without having to create intermediate collections or load all book data into memory. It's particularly suitable for large datasets.\n",
       "\n",
       "Here are some use cases where you might want to use this approach:\n",
       "\n",
       "* Processing a list of articles with various metadata, like author profiles.\n",
       "* Retrieving data from an API that returns book objects or documents with complex structures (e.g., author information).\n",
       "\n",
       "Example usage:\n",
       "```python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": None},\n",
       "    {\"title\": \"Book 3\", \"author\": \"Author C\"}\n",
       "]\n",
       "\n",
       "for author in get_authors(books):\n",
       "    print(author)\n",
       "```\n",
       "Output:\n",
       "```\n",
       "Author A\n",
       "None\n",
       "Author C\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "stream_answer(ollama, question, MODEL_LLAMA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
